{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38bb0ce4-c656-4042-947f-217fd183a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e1ef70d-0441-4422-b4d0-1c44a87ed20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset\\\\cats\\\\Data'\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "batch_size = 128\n",
    "img_size = (64, 64) # (width, height)\n",
    "\n",
    "input_dim = 3 * 64 * 64\n",
    "hidden_dim = 512\n",
    "latent_dim = 16\n",
    "n_embeddings= 512\n",
    "output_dim = 3 * 64 * 64\n",
    "commitment_beta = 0.25\n",
    "\n",
    "lr = 2e-4\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "079ad58d-bc71-42a2-a45b-ce2f7b3fe35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.file_list[idx]\n",
    "        img = Image.open(path)\n",
    "        return transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23c280f2-efb5-4f18-b49c-5e37c9407dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((64,64)), transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "files = [os.path.join(data_path, line.strip()) for line in os.listdir(data_path)]\n",
    "dataset = CatDataset(files, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0345d617-91bb-432a-b56f-712f32a1c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_mean  = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.FC_var   = nn.Linear (hidden_dim, latent_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.training = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_       = self.LeakyReLU(self.FC_input(x))\n",
    "        h_       = self.LeakyReLU(self.FC_input2(h_))\n",
    "        mean     = self.FC_mean(h_)\n",
    "        log_var  = self.FC_var(h_)                     # encoder produces mean and log of variance \n",
    "                                                       #             (i.e., parameters of simple tractable normal distribution \"q\"\n",
    "        \n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "74d5f976-8b51-4bef-90f0-67be4577af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h     = self.LeakyReLU(self.FC_hidden(x))\n",
    "        h     = self.LeakyReLU(self.FC_hidden2(h))\n",
    "        \n",
    "        x_hat = torch.sigmoid(self.FC_output(h))\n",
    "        x_hat = x_hat.view(-1, self.output_dim)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82f2b2ae-a550-4928-9883-17b58ac0ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + var*epsilon                          # reparameterization trick\n",
    "        return z\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat = self.Decoder(z)\n",
    "        \n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c0a939ae-9bb3-4943-a676-455b00f0b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim=input_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = input_dim)\n",
    "\n",
    "model = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8fdd3e9b-939f-4eae-8d29-0b68e3bfd6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "BCE_loss = nn.BCELoss()\n",
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "    return reproduction_loss + KLD\n",
    "\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6cf29b63-8ad7-4e67-8e42-02cb60cc3efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VAE...\n",
      "\tEpoch 1 complete! \tAverage Loss:  7686.889121820863\n",
      "\tEpoch 2 complete! \tAverage Loss:  7326.677380373957\n",
      "\tEpoch 3 complete! \tAverage Loss:  7226.854448698187\n",
      "\tEpoch 4 complete! \tAverage Loss:  7189.889123915156\n",
      "\tEpoch 5 complete! \tAverage Loss:  7157.862643668532\n",
      "\tEpoch 6 complete! \tAverage Loss:  7138.695481352411\n",
      "\tEpoch 7 complete! \tAverage Loss:  7130.442674999163\n",
      "\tEpoch 8 complete! \tAverage Loss:  7111.999155999732\n",
      "\tEpoch 9 complete! \tAverage Loss:  7099.561285309788\n",
      "\tEpoch 10 complete! \tAverage Loss:  7095.293289046008\n",
      "\tEpoch 11 complete! \tAverage Loss:  7091.4005776061385\n",
      "\tEpoch 12 complete! \tAverage Loss:  7088.033328586268\n",
      "\tEpoch 13 complete! \tAverage Loss:  7085.373984267668\n",
      "\tEpoch 14 complete! \tAverage Loss:  7082.452863736889\n",
      "\tEpoch 15 complete! \tAverage Loss:  7080.335840900714\n",
      "\tEpoch 16 complete! \tAverage Loss:  7077.8019384780355\n",
      "\tEpoch 17 complete! \tAverage Loss:  7076.178965754113\n",
      "\tEpoch 18 complete! \tAverage Loss:  7074.160954830279\n",
      "\tEpoch 19 complete! \tAverage Loss:  7071.568688637201\n",
      "\tEpoch 20 complete! \tAverage Loss:  7069.762337482827\n",
      "\tEpoch 21 complete! \tAverage Loss:  7068.196867774687\n",
      "\tEpoch 22 complete! \tAverage Loss:  7067.194880290185\n",
      "\tEpoch 23 complete! \tAverage Loss:  7064.979260211775\n",
      "\tEpoch 24 complete! \tAverage Loss:  7063.243855342961\n",
      "\tEpoch 25 complete! \tAverage Loss:  7061.84750820963\n",
      "\tEpoch 26 complete! \tAverage Loss:  7060.795846178334\n",
      "\tEpoch 27 complete! \tAverage Loss:  7059.27954419797\n",
      "\tEpoch 28 complete! \tAverage Loss:  7058.707806269477\n",
      "\tEpoch 29 complete! \tAverage Loss:  7056.6451156887715\n",
      "\tEpoch 30 complete! \tAverage Loss:  7056.025996464833\n",
      "\tEpoch 31 complete! \tAverage Loss:  7054.76099294642\n",
      "\tEpoch 32 complete! \tAverage Loss:  7053.0782616526485\n",
      "\tEpoch 33 complete! \tAverage Loss:  7051.95527845726\n",
      "\tEpoch 34 complete! \tAverage Loss:  7050.860501206313\n",
      "\tEpoch 35 complete! \tAverage Loss:  7049.8656364139\n",
      "\tEpoch 36 complete! \tAverage Loss:  7048.6513818148305\n",
      "\tEpoch 37 complete! \tAverage Loss:  7048.381846245351\n",
      "\tEpoch 38 complete! \tAverage Loss:  7046.838873437657\n",
      "\tEpoch 39 complete! \tAverage Loss:  7045.671872382133\n",
      "\tEpoch 40 complete! \tAverage Loss:  7044.790784271018\n",
      "\tEpoch 41 complete! \tAverage Loss:  7044.01537001977\n",
      "\tEpoch 42 complete! \tAverage Loss:  7043.4208964413765\n",
      "\tEpoch 43 complete! \tAverage Loss:  7042.062414133968\n",
      "\tEpoch 44 complete! \tAverage Loss:  7041.856957661763\n",
      "\tEpoch 45 complete! \tAverage Loss:  7040.283014442248\n",
      "\tEpoch 46 complete! \tAverage Loss:  7039.978240290856\n",
      "\tEpoch 47 complete! \tAverage Loss:  7038.723247495225\n",
      "\tEpoch 48 complete! \tAverage Loss:  7037.99161444895\n",
      "\tEpoch 49 complete! \tAverage Loss:  7037.2895130348825\n",
      "\tEpoch 50 complete! \tAverage Loss:  7036.551052591898\n",
      "Finish!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training VAE...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    for batch_idx, x in enumerate(loader):\n",
    "        if x.shape[0] != batch_size:\n",
    "            continue\n",
    "        \n",
    "        x = x.view(batch_size, input_dim)\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_var = model(x)\n",
    "        loss = loss_function(x, x_hat, mean, log_var)\n",
    "        \n",
    "        overall_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / len(files))\n",
    "    \n",
    "print(\"Finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9ba18261-3625-49d0-9d88-09bb7190314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9164aa3f-9a7f-4b2d-b716-fca334c63395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_image(x, idx):\n",
    "    x = x.view(10, 64, 64)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(x[idx].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "997443e3-1b12-4a28-9ea6-090ca389199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noise = torch.randn(10, latent_dim).to(DEVICE)\n",
    "    generated_images = decoder(noise)\n",
    "\n",
    "save_image(generated_images.view(10, 3, 64, 64), 'generated_sample.png', nrow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6bf079a7-d154-4f9a-a512-00d77467cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(el for el in loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0d2586c8-9756-4ec7-bcf0-b121db086398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(gen, z1, z2, steps=10):\n",
    "    alphas = torch.linspace(0,1,steps, device=DEVICE).view(-1,1,1,1)\n",
    "    zs = (1-alphas)*z1 + alphas*z2\n",
    "    with torch.no_grad(): imgs = gen(zs)\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fe8aae0e-4c37-407a-a02e-9145f18ae821",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x[0]\n",
    "x2 = x[1]\n",
    "\n",
    "x1 = x1.view(1, input_dim)\n",
    "x1 = x1.to(DEVICE)\n",
    "\n",
    "x2 = x2.view(1, input_dim)\n",
    "x2 = x2.to(DEVICE)\n",
    "\n",
    "z1, z2 = encoder(x1), encoder(x2)\n",
    "\n",
    "interp_grid = interpolate(decoder, z1[0], z2[0])\n",
    "save_image(interp_grid.view(10, 3, 64, 64), 'interpolation.png', nrow=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
